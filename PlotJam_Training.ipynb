{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PlotJam Training",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/PlotJam/blob/master/PlotJam_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "# **PlotJam Training**\n",
        "Code for fine-tuning GPT-2 to generate plot summaries.\n",
        "![alt text](https://raw.githubusercontent.com/robgon-art/gtp2-plot-generation/master/images/the_story_medium.jpg)\n",
        "Photo illustration based on a photo by alexkerhead CC By 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pQC-jFBfkvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and unzip the CMU Book Summary Dataset \n",
        "!wget -O booksummaries.tar.gz http://www.cs.cmu.edu/~dbamman/data/booksummaries.tar.gz\n",
        "!tar -xf booksummaries.tar.gz\n",
        "\n",
        "# Import support for CSV files and the JSON format\n",
        "import csv\n",
        "import json\n",
        "\n",
        "# Initialize the genre dictionary\n",
        "genre_groups = {}\n",
        "\n",
        "# Create and open the output file\n",
        "plot_file = open(\"story_plots.txt\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# Process the summaries to get the genre, title, and the plot summary\n",
        "with open('booksummaries/booksummaries.txt', newline='', encoding='utf-8') as f:\n",
        "  reader = csv.reader(f, delimiter='\\t')\n",
        "  for row in reader:\n",
        "\n",
        "    # Get the genre\n",
        "    genre_string = row[5]\n",
        "    if len(genre_string) == 0:\n",
        "      continue\n",
        "\n",
        "    # Parse the genres associated with the book\n",
        "    genre_dict = json.loads(genre_string)\n",
        "    genre_dict= {k: v for k, v in sorted(genre_dict.items(), key=lambda item: item[1])}\n",
        "    genre = \"\"\n",
        "    for key in genre_dict:\n",
        "      genre += genre_dict[key] + \", \"\n",
        "    genre = genre[:-2]\n",
        "\n",
        "    # Add the genre to the the dictionary\n",
        "    if not genre in genre_groups:\n",
        "      genre_groups[genre] = 1;\n",
        "    else:\n",
        "      genre_groups[genre] += 1\n",
        "\n",
        "    # Get the title\n",
        "    title = row[2]\n",
        "\n",
        "    # Get the plot, and keep the first part\n",
        "    plot = row[6][:500]\n",
        "    plot = plot.rsplit(' ', 1)[0] + \" ...\"\n",
        "\n",
        "    # Write the fields out to the output file\n",
        "    entry = 'GENRE: ' + genre + ' TITLE: ' + title + ' PLOT:' + plot\n",
        "    plot_file.write(entry + '\\n')\n",
        "plot_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Use TensorFlow 1.15\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Install GPT-2, download the large model, and start the session\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "model = \"774M\" # 124M 355M 774M 1558M\n",
        "gpt2.download_gpt2(model_name=model)\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "# Run the fine-tuning for 10,000 steps\n",
        "gpt2.finetune(sess, dataset='story_plots.txt', model_name=model, steps=10000,\n",
        "  restore_from='fresh', run_name='run1', print_every=10, sample_every=1000,\n",
        "  save_every=10000)\n",
        "\n",
        "# Zip up the results\n",
        "!zip -r plot_jam.zip checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
